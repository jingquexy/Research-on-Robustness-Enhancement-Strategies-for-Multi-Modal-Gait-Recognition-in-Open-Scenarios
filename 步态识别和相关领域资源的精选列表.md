# **步态识别和相关领域资源的精选列表**

# **A curated list of Gait Recognition and related area resources**

## 步态识别数据集和评估 Gait Recognition Dataset and Evaluation

#### 2006

- [A framework for evaluating the effect of view angle, clothing and carrying condition on gait recognition](https://ieeexplore.ieee.org/abstract/document/1699873/) - S. Yu et al., **ICPR2006** (⚡***CASIA-B*** [[download]](http://www.cbsr.ia.ac.cn/english/Gait%20Databases.asp))([Shiqi Yu 等, 2006](zotero://select/library/items/T2NXKZF6))
    
    - 步态识别越来越受到研究人员的关注，但目前仍没有标准的评估方法来比较不同步态识别算法的性能。本文提出了一个框架，试图解决这一问题。该框架由一个大型步态数据库、大量精心设计的实验和一些评估指标组成。数据库中有 124 个受试者，步态数据是从 11 个视角采集的。数据库中分别考虑了三种变化，即视角、服装和携带条件的变化。该数据库是现有数据库中最大的数据库之一。该框架设计了三组实验，共包括 363 个实验。提出了一些评价步态识别算法的指标。

#### 2018

- [Multi-view large population gait dataset and its performance evaluation for cross-view gait recognition](https://link.springer.com/article/10.1186/s41074-018-0039-6) - N. Takemura et al., IPSJ2018 (⚡***OUMVLP*** [[download]](http://www.am.sanken.osaka-u.ac.jp/BiometricDB/GaitMVLP.html))([Takemura 等, 2018](zotero://select/library/items/VQUAL5XT))
    
    - 本文介绍了世界上最大的具有广泛视角变化的步态数据库--"OU-ISIR 步态数据库，多视角大群体数据集（OU-MVLP）"，并将其应用于对基于视觉的跨视角步态识别进行统计上可靠的性能评估。具体来说，我们构建了一个步态数据集，其中包括来自 0°-90°、180°-270° 等 14 个视角的 10307 名受试者（5114 名男性和 5193 名女性）。此外，我们还评估了对视角具有鲁棒性的各种步态识别方法。通过使用我们的数据集，我们可以充分利用需要大量训练样本的先进方法，例如基于 CNN 的跨视角步态识别方法，并验证了此类方法系列的有效性。

#### 2020

- [Performance evaluation of model-based gait on multi-view very large population database with pose sequences](https://ieeexplore.ieee.org/abstract/document/9139355/) - W. An et al., TBIOM2020 (⚡***OUMVLP-Pose*** [[download]](http://www.am.sanken.osaka-u.ac.jp/BiometricDB/GaitLPPose.html))([An 等, 2020](zotero://select/library/items/5GUTH469))
    
    - 基于模型的步态识别被认为很有前景，因为它对某些变化（如衣服和携带的行李）具有鲁棒性。虽然由于人体模型拟合困难和缺乏大规模步态数据库，基于模型的步态识别尚未得到充分探索，但基于深度学习的人体模型拟合和人体姿态估计方法的最新进展正在缓解这一困难。因此，我们在本文中提出了一个基于人体姿态的大规模步态数据库 OUMVLP-Pose，该数据库基于公开的多视角大规模步态数据库 OUMVLP，从而解决了余下的问题。与其他公开数据库相比，OUMVLP-Pose 具有许多独特的优势。首先，OUMVLP-Pose 是首个步态数据库，它提供了由 OpenPose 和 AlphaPose 两种基于深度学习的标准姿势估计算法提取的两个人体姿势序列数据集。其次，它包含多视角大规模数据，即超过 10,000 个受试者和每个受试者的 14 个视角。此外，我们还提供了基准，对不同类型的步态识别方法进行了全面评估，包括基于模型的方法和基于外观的方法。基于模型的步态识别方法表现出了良好的性能。我们相信，OUMVLPPose 这个数据库将在未来几年极大地推动基于模型的步态识别。

#### 2021

- [Gait recognition in the wild: A benchmark](http://openaccess.thecvf.com/content/ICCV2021/html/Zhu_Gait_Recognition_in_the_Wild_A_Benchmark_ICCV_2021_paper.html) - Z. Zhu et al., **ICCV2021**(⚡***GREW*** [[download]](https://www.grew-benchmark.org/))([Zhu 等](zotero://select/library/items/BXXTUR96))
    
    - 步态基准使研究界有能力训练和评估高性能步态识别系统。尽管人们在跨视角识别方面做出了越来越多的努力，但学术界仍受到目前在受控环境中捕获的现有数据库的限制。在本文中，我们为野外步态识别（GREW）提供了一个新的基准。GREW 数据集由自然视频构建而成，其中包含开放系统中的数百个摄像头和数千小时的视频流。通过大量人工注释，GREW 包含 26K 个身份和 128K 个序列，具有丰富的属性，可用于无约束步态识别。此外，我们还添加了超过 233K 个序列的干扰项，使其更适合真实世界的应用。与目前流行的预定义跨视图数据集相比，GREW 具有多样化和实用的视图变化，以及更多的自然挑战因素。据我们所知，这是第一个用于野生步态识别的大规模数据集。有了这个基准，我们对无约束步态识别问题进行了剖析。我们探索了具有代表性的基于外观和基于模型的方法，并建立了综合基准。实验结果表明 (1) 提议的 GREW 基准对于训练和评估野外步态识别器是必要的。(2) 对于最先进的步态识别方法来说，还有很大的改进空间。(3) GREW 基准可用作受控步态识别的有效预训练。

#### 2022

- [Gait Recognition in the Wild with Dense 3D Representations and A Benchmark](https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_Gait_Recognition_in_the_Wild_With_Dense_3D_Representations_and_CVPR_2022_paper.html) - J. Zheng et al., **CVPR2022** (⚡***Gait3D*** [[download]](https://gait3d.github.io/))([Zheng 等, 2022](zotero://select/library/items/GNSK8YW7))
    
    - 现有的步态识别研究主要采用二维表示法，如受限场景中的人体轮廓或骨架。然而，人类是在无约束的三维空间中生活和行走的，因此将三维人体投影到二维平面上会丢弃很多关键信息，如步态识别的视角、形状和动态。因此，本文旨在探索用于野外步态识别的密集三维表征，这是一个实用但被忽视的问题。特别是，我们提出了一个新颖的框架来探索用于步态识别的人体三维带皮多人线性（Skinned Multi-Person Linear Model，SMPL）模型，并将其命名为 SMPLGait。我们的框架有两个精心设计的分支，其中一个从剪影中提取外观特征，另一个从三维 SMPL 模型中学习三维视点和形状知识。此外，由于缺乏合适的数据集，我们建立了第一个基于三维表示的大规模步态识别数据集，名为 Gait3D。该数据集包含 4000 个受试者和超过 25000 个序列，这些序列是从无约束室内场景中的 39 个摄像头中提取的。更重要的是，它提供了从视频帧中恢复的三维 SMPL 模型，可以提供密集的身体形状、视角和动态三维信息。在 Gait3D 的基础上，我们将我们的方法与现有的步态识别方法进行了全面比较，这反映了我们框架的卓越性能以及三维表示法在野外步态识别中的潜力。
- [CASIA-E: A Large Comprehensive Dataset for Gait Recognition](https://ieeexplore.ieee.org/abstract/document/9796582/) - C. Song et al., **TPAMI2022** (⚡***CASIA-E*** [[download]](https://www.scidb.cn/detail?dataSetId=57be0e918db743279baf44a38d013a06))([Song 等, 2022](zotero://select/library/items/NUMBS69D))
    
    - 步态识别因其独特的优势（如远距离、跨视角和非合作性识别）在视觉监控中发挥着特殊作用。然而，它尚未得到广泛应用。造成这种尴尬局面的原因之一是缺乏在实际户外场景中捕捉到的真正大数据集。这里的 "大 "至少意味着：(1) 大量的步态视频；(2) 足够的研究对象；(3) 丰富的属性；(4) 时空变化。此外，现有的大规模步态数据集大多是在室内采集的，很少有真实场景的挑战，如动态复杂的背景杂波、光照变化、垂直视角变化等。本文将介绍一个新建立的大型室外步态数据集，名为 CASIA-E。该数据集包含一千多个人，分布在近一百万个视频中。每个人都有 26 个视角，并因背包、穿衣和走路方式的变化而呈现出不同的外观。这些视频的拍摄时间跨度长达五个月，涉及三种室外场景。我们还记录了所有对象的软生物特征，包括年龄、性别、身高、体重和国籍。此外，我们还报告了一个实验基准，并研究了一些以前没有很好研究过的有意义的问题，例如百万级别训练视频、垂直视角、行走方式和热红外模式的影响。我们相信，这样一个大型室外数据集和实验基准将促进步态识别在学术研究和工业应用两方面的发展。
- [Multi-view large population gait database with human meshes and its performance evaluation](https://ieeexplore.ieee.org/abstract/document/9773349/) - X. Li et al., TBIOM 2022 （⚡***OUMVLP-Mesh*** [[download]](http://www.am.sanken.osaka-u.ac.jp/BiometricDB/GaitLPMesh.html)）([Li 等, 2022](zotero://select/library/items/ZQYSRG35))
    
    - 现有的基于模型的步态数据库提供由一般姿势估计器提取的二维姿势（即关节位置）作为人体模型。然而，这些二维姿势存在信息损失，质量相对较低。在本文中，我们考虑了具有参数化姿势和形状特征的信息量更大的三维人体网格模型，并提出了一种多视角训练框架，以实现精确的网格估计。现有方法仅从单一视角估计网格，存在三维空间中的估计问题，与之不同的是，本文提出的框架以异步多视角步态序列为输入，同时使用多视角和单视角数据流，为多视角和单视角序列学习一致且精确的网格模型。将所提出的框架应用于现有的 OU-MVLP 数据库后，我们建立了一个包含人体网格的大规模步态数据库（即 OUMVLP-Mesh），其中包含 10,000 多个受试者和多达 14 个视角。实验结果表明，与同类方法相比，提议的框架能更准确地估计人体网格模型，提供的模型质量足以提高基于模型的基线步态识别方法的识别性能。
- [Front View Gait (FVG-B) Database](http://cvlab.cse.msu.edu/pdfs/FVG_B_Report.pdf) - Y. Su et al., Univer Web (⚡***FVG-B*** [[download]](http://cvlab.cse.msu.edu/frontal-view-gaitfvg-database.html))([Su 和 Liu](zotero://select/library/items/8I9FD4XX))
    
    - 为了促进步态识别研究，我们在 2017 年和 2018 年两年时间里收集了前视步态（FVG）数据库。为了更好地保护受试者的隐私，我们创建了一个名为 FVG-B 的数据库版本，其中的人脸区域被模糊化，以至于最先进的人脸识别算法无法识别受试者。在本报告中，我们将介绍制作 FVG-B 数据库的技术细节。

#### 2023

- [Gait Recognition with Drones: A Benchmark](https://ieeexplore.ieee.org/abstract/document/10243069/) - A. Li et al., **TMM2023** (⚡***DroneGait*** [[download]](https://github.com/BNU-IVC/DroneGait))
    
    - 步态识别的目的是通过体形和走路姿势来识别人的身份。现有的步态识别研究侧重于低垂直视角下的识别，即人和摄像机几乎处于同一高度。与此不同的是，在这项工作中，我们专注于高垂直视角下的步态识别。为了便于研究，我们提出了一个名为 DroneGait 的新数据集，使用无人机收集步态数据。该数据集包含 96 名受试者在不同垂直视角下拍摄的 22 k 个序列，视角从 0 o 到 80 o 不等。此外，我们还使用我们的数据集评估了几种最先进的基于外观和骨架的模型的有效性，并建立了综合基线。我们的结果表明，该数据集具有挑战性，为改进现有步态识别方法提供了重要机会。此外，我们还提出了一种名为 "垂直蒸馏 "的新方法，该方法基于不同垂直视图的特征蒸馏。在高垂直视图下，我们提出的方法大大优于 DroneGait 上最先进的模型。我们还进行了跨垂直视角和跨领域实验，以解释高垂直视角下步态识别的重要性。此外，我们还利用热图可视化技术分析了不同垂直视角下步态识别的差异。
- [LIDAR GAIT: Benchmarking 3D Gait Recognition with Point Clouds](https://arxiv.org/abs/2211.10598) - C. Shen et al., **CVPR2023** (⚡***SUSTech1K*** [[download]](https://lidargait.github.io/))([Shen 等, 2023](zotero://select/library/items/XANQESAV))
    
    - 基于视频的步态识别在受限场景中取得了令人瞩目的成果。然而，视觉相机忽略了人体三维结构信息，这限制了在三维野生环境中进行步态识别的可行性。这项工作不是从图像中提取步态特征，而是从点云中探索精确的三维步态特征，并提出了一个简单而高效的三维步态识别框架，称为 **LidarGait**。我们提出的方法将稀疏的点云投射到深度图中，以学习具有三维几何信息的表征，其效果明显优于现有的基于点的方法和基于摄像头的方法。由于缺乏点云数据集，我们建立了第一个基于激光雷达的大规模步态识别数据集 SUSTech1K，该数据集由激光雷达传感器和 RGB 摄像机采集。该数据集包含来自 1,050 名受试者的 25,239 个序列，涵盖多种变化，包括可见度、视图、遮挡物、服装、携带和场景。大量实验表明：（1）三维结构信息是步态识别的重要特征。(2) LidarGait 的性能明显优于现有的基于点和剪影的方法，同时它还能提供稳定的跨视角结果。(3) 在室外环境中，激光雷达传感器在步态识别方面优于 RGB 摄像机。
- [An In-Depth Exploration of Person Re-Identification and Gait Recognition in Cloth-Changing Conditions](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_An_In-Depth_Exploration_of_Person_Re-Identification_and_Gait_Recognition_in_CVPR_2023_paper.pdf) - W. Li et al. **CVPR2023** (⚡***CCPG*** [[download]](https://github.com/BNU-IVC/CCPG))([Li 等, 2023](zotero://select/library/items/W24XXB53))
    
    - 人员再识别（ReID）和步态识别的目标是一致的，即在监控摄像机下与目标行人相匹配。对于换衣问题，由于缺乏合适的换衣基准，基于视频的再识别研究很少，而步态识别通常是在受控条件下研究的。为了解决这个问题，我们提出了用于人员再识别和步态识别的换衣基准（CCPG）。这是一个换衣数据集，CCPG 有几个亮点：（1）它提供了 200 个身份和超过 16K 个室内外序列；（2）每个身份有 7 种不同的换衣状态，这在以前的数据集中很少见；（3）RGB 和剪影版本数据都可供研究使用。此外，为了系统地研究换衣问题，还对基于视频的 ReID 和步态识别方法进行了综合实验。实验结果表明，在不同的换衣条件下，ReID 和步态识别分别具有优越性，并表明步态识别是解决换衣问题的潜在解决方案。
- [Learning Gait Representation from Massive Unlabelled Walking Videos: A Benchmark](https://ieeexplore.ieee.org/document/10242019) - C. Fan et al. **TPAMI2023** (⚡***GaitLU-1M*** [[download]](https://github.com/ShiqiYu/OpenGait/blob/master/datasets/GaitLU-1M/README.md))([Fan 等, 2023](zotero://select/library/items/3V4P8F22))
    
    - 步态描述了个人独特而有区别的行走模式，已成为最有前途的人体识别生物特征之一。作为一项细粒度识别任务，步态识别容易受到多种因素的影响，通常需要大量完整标注的数据，成本高昂且难以满足。本文提出了一种利用对比学习进行步态识别的大规模自监督基准，旨在通过提供翔实的步行先验数据和多样化的真实世界变化，从海量无标签步行视频中学习一般步态表示，以用于实际应用。具体来说，我们收集了一个由 102 万个行走序列组成的大规模无标签步态数据集 GaitLU-1M，并提出了一个概念上简单但经验上强大的基线模型 GaitSSB。实验中，我们在四个广泛使用的步态基准（CASIA-B、OU-MVLP、GREW 和 Gait3D）上对预训练模型进行了评估，无论是否有迁移学习。无监督结果与早期基于模型和基于 GEI 的方法相当，甚至更好。经过迁移学习后，GaitSSB 在大多数情况下都大大优于现有方法，同时也展示了其卓越的泛化能力。进一步的实验表明，预训练可以为 GREW 和 Gait3D 节省约 50% 和 80% 的标注成本。从理论上讲，我们讨论了步态特定对比框架的关键问题，并提出了一些供进一步研究的见解。据我们所知，GaitLU-1M 是第一个大规模无标签步态数据集，而 GaitSSB 则是第一个在上述基准上取得显著无监督结果的方法。

#### **AAAI2024**

- [Cross-Covariate Gait Recognition: A Benchmark](https://arxiv.org/abs/2312.14404) - S. Zou et al. (⚡***CCRG*** [[download]](https://github.com/ShinanZou/CCGR))([Zou 等, 2024](zotero://select/library/items/RWDFBA6Y))
    
    - 步态数据集对步态研究至关重要。然而，本文发现，无论是传统的受限数据集还是新兴的真实世界数据集，目前的基准在协变量多样性方面都存在不足。为了弥补这一不足，我们进行了为期 20 个月的艰苦努力，以收集跨协变步态识别（CCGR）数据集。CCGR 数据集有 970 个受试者和约 160 万个序列；几乎每个受试者都有 33 个视图和 53 个不同的协变量。与现有数据集相比，CCGR 同时具有群体和个体层面的多样性。此外，视图和协变量都有很好的标记，可以分析不同因素的影响。CCGR 提供多种类型的步态数据，包括 RGB、解析、剪影和姿势，为研究人员提供了全面的探索资源。为了更深入地解决跨变量步态识别问题，我们利用新提出的解析数据，提出了基于解析的步态识别（ParsingGait）。我们进行了广泛的实验。我们的主要结果表明1) 交叉变量成为步态识别实际应用中的一个关键挑战。2) ParsingGait 展示了进一步发展的巨大潜力。3) 令人震惊的是，现有的 SOTA 方法在 CCGR 上的准确率不到 43%，这凸显了探索跨变量步态识别的紧迫性。

## 基于外观的步态识别 Appearance based Gait Recognition（轮廓/Silhouette）

### 2019

#### **AAAI2019**

- [Gaitset: Regarding gait as a set for cross-view gait recognition](https://ojs.aaai.org/index.php/AAAI/article/view/4821) - H. Chao et al., AAAI2019 (⚡***GaitSet*** [[Official Code](https://github.com/AbnerHqC/GaitSet), [OpenGait](https://github.com/ShiqiYu/OpenGait/)] )([Chao 等, 2019](zotero://select/library/items/96XFGZSH))
    
    - **将步态视为跨视角步态识别的集合**
    - 步态作为一种可远距离识别的独特生物特征，在预防犯罪、法医鉴定和社会安全方面有着广泛的应用。为了描绘步态，现有的步态识别方法要么使用步态模板（很难保留时间信息），要么使用步态序列（必须保留不必要的序列约束，从而失去步态识别的灵活性）。在本文中，我们提出了一个新的视角，即将步态视为由独立帧组成的集合。我们提出了一种名为 GaitSet 的新网络，用于从集合中学习身份信息。基于集合视角，我们的方法不受帧的排列影响，可以自然地整合不同视频中不同场景下拍摄的帧，如不同的视角、不同的衣服/携带条件。实验表明，在正常行走条件下，我们的单一模型方法在 CASIA-B 步态数据集上的平均 rank-1 准确率为 95.0%，在 OU-MVLP 步态数据集上的平均 rank-1 准确率为 87.1%。这些结果代表了最新的识别准确率。在各种复杂场景中，我们的模型表现出了显著的鲁棒性。在背着包和穿着外套行走的情况下，它在 CASIA-B 上的准确率分别达到了 87.2% 和 70.4%。这大大超过了现有的最佳方法。该方法还能在测试样本帧数较少的情况下达到令人满意的准确度，例如，在 CASIA-B 中仅用 7 个帧就达到了 82.5%。

#### **CVPR2019**

- [Gait recognition via disentangled representation learning](http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Gait_Recognition_via_Disentangled_Representation_Learning_CVPR_2019_paper.html) - Z. Zhang et al. ✨ **Oral Paper** ✨([Zhang 等, 2019](zotero://select/library/items/53TTZDC9))
    
    - **通过分离表征学习进行步态识别**
    - 步态，即个人的行走模式，是最重要的生物统计学模式之一。现有的步态识别方法大多采用剪影或铰接人体模型作为步态特征。这些方法在处理服装、携带和视角等混杂变量时会降低识别性能。为了解决这个问题，我们提出了一个新颖的自动编码器框架，明确地从 RGB 图像中分离出姿势和外观特征，并通过基于 LSTM 的随时间变化的姿势特征整合生成步态特征。此外，我们还收集了一个正面视图步态（FVG）数据集，重点研究正面视图行走的步态识别，这是一个具有挑战性的问题，因为与其他视图相比，它包含的步态线索极少。FVG 还包括其他重要的变化，如行走速度、携带和服装。通过在 CASIA-B、USF 和 FVG 数据集上的大量实验，我们的方法在定量上表现出优于同行的性能，在定性上表现出特征分离的能力，并且在计算效率上也大有可为。

### 2020

#### **CVPR2020**

- [Gaitpart: Temporal part-based model for gait recognition](http://openaccess.thecvf.com/content_CVPR_2020/html/Fan_GaitPart_Temporal_Part-Based_Model_for_Gait_Recognition_CVPR_2020_paper.html) - C. Fan et al. (⚡***GaitPart*** [[OpenGait]](https://github.com/ShiqiYu/OpenGait/))([Fan 等, 2020](zotero://select/library/items/2AKFTYPU))
    
    - 步态识别用于识别个人远距离行走模式，是最有前途的基于视频的生物识别技术之一。目前，大多数步态识别方法都是以整个人体为单位建立时空表征。然而，我们观察到，人体的不同部位在行走时具有明显不同的视觉外观和运动模式。在最新的文献中，采用局部特征来描述人体已被证实有利于个体识别。综合上述观点，我们认为人体的每个部位都需要自己的时空表达。然后，我们提出了一个基于部分特征的新模型 GaitPart，并取得了两方面的效果：一方面，我们提出了一种新的卷积应用--焦点卷积层（Focal Convolution Layer），以增强对部分级空间特征的精细学习。另一方面，提出了微运动捕捉模块（MCM），在 GaitPart 中有多个并行的 MCM，分别对应人体的预定义部位。值得一提的是，MCM 是一种新颖的步态任务时间建模方法，它侧重于短程时间特征，而不是周期步态的冗余长程特征。在 CASIA-B 和 OU-MVLP 这两个最流行的公共数据集上进行的实验充分证明，我们的方法在多个标准基准上达到了新的先进水平。

#### **ECCV2020**

- [Gait lateral network: Learning discriminative and compact representations for gait recognition](https://link.springer.com/chapter/10.1007/978-3-030-58545-7_22) - S. You et al. (⚡***GLN*** [[OpenGait]](https://github.com/ShiqiYu/OpenGait/))([Hou 等, 2020](zotero://select/library/items/3C652E6D))
    
    - 步态识别的目的是通过行走模式识别不同的人，这种识别可以在远距离进行，无需被试的配合。步态识别的一个关键挑战是从剪影中学习不受服装、携带条件和相机视角等因素影响的表征。步态表征除了在识别方面具有辨别力外，还应该便于存储，以便在图库中保存数百万个注册对象。在这项工作中，我们提出了一种名为 "步态侧向网络"（GLN）的新型网络，它可以从剪影中学习到既有辨别力又紧凑的步态识别表征。具体来说，GLN 利用深度卷积神经网络固有的特征金字塔来增强步态表征。不同阶段提取的剪影级和集合级特征以自上而下的方式与横向联系合并。此外，GLN 还配备了一个 "紧凑块"（Compact Block），可以在不影响准确性的前提下显著降低步态表征的维度。在 CASIA-B 和 OUMVLP 上进行的大量实验表明，GLN 在使用 256 维表示时可以达到最先进的性能。在 CASIA-B 上穿着不同衣服行走这一最具挑战性的条件下，我们的方法将rank-1 的准确率提高了 6.45%。

### 2021

#### **ICCV2021**

- [3d local convolutional neural networks for gait recognition](http://openaccess.thecvf.com/content/ICCV2021/html/Huang_3D_Local_Convolutional_Neural_Networks_for_Gait_Recognition_ICCV_2021_paper.html) - Z. Huang et al. (⚡***3DLocal*** [[Official Code]](https://github.com/aliyun/3D-Local-CNN-for-Gait-Recognition))([Huang 等, 2021](zotero://select/library/items/NVYPK2MN))
    
    - 步态识别的目标是从时间变化特征中学习人体形状的独特时空模式。由于不同身体部位在行走过程中的表现各不相同，因此直观的做法是对每个部位的时空模式分别建模。然而，现有的基于部位的方法是将每帧的特征图平均分成固定的水平条纹，从而得到局部部位。显然，这些基于条纹分割的方法无法准确定位身体部位。首先，不同的身体部位可能出现在同一条纹上（如手臂和躯干），一个部位也可能出现在不同帧的不同条纹上（如手）。其次，不同的身体部位具有不同的比例，甚至同一部位在不同画面中出现的位置和比例也可能不同。第三，不同部位也会表现出不同的运动模式（例如，从哪一帧开始运动、位置变化频率、持续时间）。为了克服这些问题，我们提出了新颖的三维局部操作，作为三维步态识别骨干的通用构建模块系列。所提出的三维局部运算支持在具有自适应时空尺度、位置和长度的序列中提取身体部位的局部三维体积。这样，身体部位的时空模式就能很好地从特定尺度、位置、频率和长度的三维局部邻域中学习到。实验证明，我们的三维局部卷积神经网络在流行的步态数据集上实现了最先进的性能。
- [Context-sensitive temporal feature learning for gait recognition](http://openaccess.thecvf.com/content/ICCV2021/html/Huang_Context-Sensitive_Temporal_Feature_Learning_for_Gait_Recognition_ICCV_2021_paper.html) - X. Huang et al.(⚡***CSTL***[[Official Code]](https://github.com/OliverHxh/CSTL))([Huang 等, 2021](zotero://select/library/items/85JLDXDA))
    
    - 虽然步态识别最近引起了越来越多的研究关注，但由于空间域中的轮廓差异相当微妙，因此学习具有区分性的时间表示仍然具有挑战性。人类可以通过自适应地关注不同时间尺度的时间序列来区分不同主体的步态，受这一观察结果的启发，我们在本文中提出了一种上下文敏感时间特征学习（CSTL）网络，该网络将三个尺度的时间特征聚合在一起，从而根据时间上下文信息获得运动表征。具体来说，CSTL 引入了多尺度特征之间的关系建模来评估特征的重要性，在此基础上，网络自适应地增强较重要的尺度，抑制较不重要的尺度。此外，我们还提出了突出空间特征学习（SSFL）模块，以解决由时序操作（如时序卷积）引起的错位问题。突出空间特征学习模块通过提取整个序列中最具区分度的部分，重新组合一帧突出空间特征。这样，我们就同时实现了自适应时间学习和突出空间挖掘。在两个数据集上进行的广泛实验证明了这一技术的先进性。在 CASIA-B 数据集上，在正常行走、背包和穿外套的条件下，我们的排名-1 准确率分别达到 98.0%、95.4% 和 87.0%。在 OU-MVLP 数据集上，我们取得了 90.2% 的一级准确率。
- [Gait recognition via effective global-local feature representation and local temporal aggregation](http://openaccess.thecvf.com/content/ICCV2021/html/Lin_Gait_Recognition_via_Effective_Global-Local_Feature_Representation_and_Local_Temporal_ICCV_2021_paper.html) - B. Lin et al. (⚡***GaitGL*** [[OpenGait]](https://github.com/ShiqiYu/OpenGait/))([Lin 等, 2021](zotero://select/library/items/D45MVD46))
    
    - 步态识别是最重要的生物识别技术之一，已被应用于许多领域。最近的步态识别框架通过从人类的整体外观或局部区域提取的描述符来表示每个步态帧。然而，基于全局信息的表征往往会忽略步态帧的细节，而基于局部区域的描述符则无法捕捉相邻区域之间的关系，从而降低了其识别性。在本文中，我们提出了一种新颖的特征提取和融合框架，以实现步态识别的判别特征表示。为此，我们利用全局视觉信息和局部区域细节，开发了全局和局部特征提取器（GLFE）。具体来说，我们的 GLFE 模块由新设计的多重全局和局部卷积层（GLConv）组成，以一种原则性的方式集合全局和局部特征。此外，我们还提出了一种新颖的操作，即局部时空聚合（LTA），通过降低时间分辨率来获得更高的空间分辨率，从而进一步保留空间信息。在 GLFE 和 LTA 的帮助下，我们的方法显著提高了视觉特征的辨别能力，从而提高了步态识别性能。广泛的实验证明，在两个流行的数据集上，我们提出的方法优于最先进的步态识别方法。
- [Gait recognition in the wild: A benchmark](http://openaccess.thecvf.com/content/ICCV2021/html/Zhu_Gait_Recognition_in_the_Wild_A_Benchmark_ICCV_2021_paper.html) - Z. Zhu et al.(⚡***GREW*** [[code]](https://github.com/GREW-Benchmark/GREW-Benchmark))([Zhu 等](zotero://select/library/items/BXXTUR96))
    
    - 步态基准使研究界有能力训练和评估高性能步态识别系统。尽管人们在跨视角识别方面做出了越来越多的努力，但学术界仍受到目前在受控环境中捕获的现有数据库的限制。在本文中，我们为野外步态识别（GREW）提供了一个新的基准。GREW 数据集由自然视频构建而成，其中包含开放系统中的数百个摄像头和数千小时的视频流。通过大量人工注释，GREW 包含 26K 个身份和 128K 个序列，具有丰富的属性，可用于无约束步态识别。此外，我们还添加了超过 233K 个序列的分心集，使其更适合真实世界的应用。与目前流行的预定义跨视图数据集相比，GREW 具有多样化和实用的视图变化，以及更多的自然挑战因素。据我们所知，这是第一个用于野生步态识别的大规模数据集。有了这个基准，我们对无约束步态识别问题进行了剖析。我们探索了具有代表性的基于外观和基于模型的方法，并建立了综合基准。实验结果表明 (1) 提议的 GREW 基准对于训练和评估野外步态识别器是必要的。(2) 对于最先进的步态识别方法来说，还有很大的改进空间。(3) GREW 基准可用作受控步态识别的有效预训练。

#### **ICIP2021**

- [Silhouette-based view-embeddings for gait recognition under multiple views](https://ieeexplore.ieee.org/abstract/document/9506238/) - T. Chai et al.(⚡***Vi-GaitGL*** [[code]](https://github.com/ctrasd/gait-view))([Chai 等, 2021](zotero://select/library/items/PWJNSZ87))
    
    - 多视角下的步态识别是一项重要的计算机视觉和模式识别任务。在新出现的基于卷积神经网络的方法中，视角信息在一定程度上被忽略了。我们提出了一个兼容的框架，可以将视角信息嵌入到现有的步态识别架构中，而不是直接进行视角估计和训练特定视角的识别模型。嵌入只需通过选择性投影层即可实现。在两个大型公共数据集上的实验结果表明，所提出的框架非常有效。

### 2022

#### **CVPR2022**

- [Lagrange Motion Analysis and View Embeddings for Improved Gait Recognition](https://openaccess.thecvf.com/content/CVPR2022/html/Chai_Lagrange_Motion_Analysis_and_View_Embeddings_for_Improved_Gait_Recognition_CVPR_2022_paper.html) - T. Chai et al. (⚡***LagrangeGait*** [[Official Code]](https://github.com/ctrasd/LagrangeGait))([Chai 等, 2022](zotero://select/library/items/EIPUSW9B))
    
    - 步态被认为是人体的行走模式，包括形状和运动线索。然而，主流的基于外观的步态识别方法依赖于轮廓的形状。步态序列建模是否能明确表示运动，目前尚不清楚。在本文中，我们利用拉格朗日方程对人类行走进行了分析，并得出结论：时间维度上的二阶信息是识别所必需的。根据得出的结论，我们设计了一个二阶运动提取模块。此外，通过分析当前跨视图任务方法没有明确考虑视图本身的问题，我们设计了一个轻量级视图嵌入模块。在 CASIA-B 和 OU-MVLP 数据集上的实验显示了我们方法的有效性，并对提取的运动进行了可视化处理，以显示我们运动提取模块的可解释性。
- [Gait Recognition in the Wild with Dense 3D Representations and A Benchmark](https://openaccess.thecvf.com/content/CVPR2022/html/Zheng_Gait_Recognition_in_the_Wild_With_Dense_3D_Representations_and_CVPR_2022_paper.html) - J. Zheng et al. (⚡***Gait3D*** [[Official Code]](https://github.com/Gait3D/Gait3D-Benchmark))([Zheng 等, 2022](zotero://select/library/items/GNSK8YW7))
    
    - 现有的步态识别研究主要采用二维表示法，如受限场景中的人体轮廓或骨架。然而，人类是在无约束的三维空间中生活和行走的，因此将三维人体投影到二维平面上会丢弃很多关键信息，如步态识别的视角、形状和动态。因此，本文旨在探索用于野外步态识别的密集三维表征，这是一个实用但被忽视的问题。特别是，我们提出了一个新颖的框架来探索用于步态识别的人体三维带皮多人线性（SMPL）模型，并将其命名为 SMPLGait。我们的框架有两个精心设计的分支，其中一个从剪影中提取外观特征，另一个从三维 SMPL 模型中学习三维视点和形状知识。此外，由于缺乏合适的数据集，我们建立了第一个基于三维表示的大规模步态识别数据集，名为 Gait3D。该数据集包含 4000 个受试者和超过 25000 个序列，这些序列是从无约束室内场景中的 39 个摄像头中提取的。更重要的是，它提供了从视频帧中恢复的三维 SMPL 模型，可以提供密集的身体形状、视角和动态三维信息。在 Gait3D 的基础上，我们将我们的方法与现有的步态识别方法进行了全面比较，这反映了我们框架的卓越性能以及三维表示法在野外步态识别中的潜力。

#### **ECCV2022**

- [Metagait: Learning to learn an omni sample adaptive representation for gait recognition](https://link.springer.com/chapter/10.1007/978-3-031-20065-6_21) - H. Dou et al. (⚡**MetaGait** [[Official Code]](https://github.com/WhiteDOU/MetaGait))([Dou 等, 2022](zotero://select/library/items/K9FF29UK))
    
    - 步态识别旨在通过行走模式识别个体，近年来已引起越来越多的研究关注。然而，步态识别仍然面临着有限的二元轮廓视觉线索与众多不同尺度的协变量之间的冲突，这给模型的适应性带来了挑战。在本文中，我们通过开发一种新型 MetaGait 来解决这一矛盾，这种 MetaGait 可以学习全样本自适应表示。为了实现这一目标，MetaGait 在注意力机制的校准网络中注入了元知识，元知识可以引导模型感知特定样本的属性，从而从全尺度、全维度和全过程的角度提高适应性。具体来说，我们利用贯穿整个过程的元知识，分别提出了元三重注意和元时空汇集，以同时从空间/通道/时空维度自适应地捕捉全尺度依赖性，并通过整合三种互补时空汇集方法的优点，自适应地汇集时空信息。广泛的实验证明了所提出的 MetaGait 具有最先进的性能。在 CASIA-B 上，我们在三种条件下的排名-1 准确率分别达到 98.7%、96.0% 和 89.3%。在 OU-MVLP 上，我们的排名-1 准确率达到 92.4%。
- [GaitEdge: Beyond Plain End-to-end Gait Recognition for Better Practicality](https://arxiv.org/abs/2203.03972) - J. Liang et al. (⚡***GaitEdge*** [[OpenGait]](https://github.com/ShiqiYu/OpenGait/))([Liang 等, 2022](zotero://select/library/items/YGGDFFQ6))
    
    - 步态是最有希望远距离识别个人的生物识别技术之一。虽然以前的大多数方法都侧重于识别轮廓，但直接从 RGB 图像中提取步态特征的几种端到端方法表现更好。然而，我们发现这些端到端方法不可避免地会受到步态相关噪声（即低级纹理和色彩信息）的影响。在实验中，我们设计了跨领域评估来支持这一观点。在这项工作中，我们提出了一种名为 GaitEdge 的新型端到端框架，它能有效屏蔽步态无关信息，释放端到端训练潜力。具体来说，GaitEdge 会合成行人分割网络的输出，然后反馈给后续的识别网络，其中合成的轮廓由可训练的身体边缘和固定的内部组成，以限制识别网络接收到的信息。此外，用于对齐剪影的 GaitAlign 被嵌入到 GaitEdge 中，而不会失去可区分性。在 CASIA-B 和我们新开发的 TTG-200 上的实验结果表明，GaitEdge 明显优于以前的方法，并提供了一种更实用的端到端范例。

### 2023

#### **IJCB2023**

- [A Multi-Stage Adaptive Feature Fusion Neural Network for Multimodal Gait Recognition](https://arxiv.org/abs/2312.14410) - S. Zou et.al. (⚡***MSAFF*** [[code]](https://github.com/ShinanZou/MSAFF))([Zou 等, 2023](zotero://select/library/items/4AMZP4FS))
    
    - 步态识别是一项受到广泛关注的生物识别技术。现有的步态识别算法大多是单模态的，少数多模态步态识别算法只进行一次多模态融合。这些算法都无法充分利用多模态的互补优势。本文通过考虑步态数据的时间和空间特征，提出了一种多阶段特征融合策略（MSFFS），在特征提取过程的不同阶段执行多模态融合。此外，我们还提出了一种自适应特征融合模块（AFFM），该模块考虑了剪影与骨骼之间的语义关联。融合过程将不同的剪影区域与其更相关的骨架关节融合在一起。由于视觉外观变化和时间流逝同时出现在步态期间，我们提出了多尺度时空特征提取器（MSSTFE）来全面学习时空联系特征。具体来说，MSSTFE 提取并聚合不同空间尺度的时空联系信息。结合上述策略和模块，我们提出了一种多级自适应特征融合（MSAFF）神经网络，该网络在三个数据集的多次实验中表现出了一流的性能。此外，MSAFF 还配备了特征维度池化（FD Pooling）功能，可以在不影响准确性的前提下显著降低步态表征的维度。

#### **MM2023**

- [LandmarkGait: Intrinsic Human Parsing for Gait Recognition](https://dl.acm.org/doi/abs/10.1145/3581783.3611840) - Z. Wang et al. (⚡***LandmarkGait*** [[code]](https://github.com/wzb-bupt/LandmarkGait))([Wang 等, 2023](zotero://select/library/items/JGD7U8Z6))
    
    - 步态识别是一种新兴的生物识别技术，可根据行人独特的行走模式对其进行识别。在过去的步态识别中，基于全局的方法不足以满足日益增长的准确性需求，而常用的基于部位的方法则对特定身体部位提供粗糙和不准确的特征表示。人体解析似乎是在步态识别中准确表示具体和完整身体部位的更好选择。然而，其在步态识别中的实际应用往往受到 RGB 模式缺失、缺乏身体部位注释以及解析数量和质量难以平衡等问题的阻碍。为了解决这个问题，我们提出了 LandmarkGait，一种基于解析的步态识别解决方案。LandmarkGait 引入了无监督地标发现网络，将密集的轮廓转化为有限的地标集，在各种条件下都具有显著的一致性。通过将与不同身体部位区域相对应的地标子集分组，并根据重构任务和高质量输入剪影的进一步细化，我们可以在无监督的情况下直接从原始二进制剪影中获得细粒度解析结果。此外，我们还开发了一种多尺度特征提取器，可根据特定身体部位的完整性和灵活性同时捕捉全局和解析特征表征。广泛的实验证明，我们的 LandmarkGait 可以在各种条件下提取出更稳定的特征，并在所有条件下表现出显著的技能提升，尤其是在多种着装条件下的表现。
- [Parsing is All You Need for Accurate Gait Recognition in the Wild](https://dl.acm.org/doi/10.1145/3581783.3612052) - J. Zheng et al. (⚡***ParsingGait*** [[code]](https://github.com/ShiqiYu/OpenGait)) ✨ **Oral Paper** ✨([Zheng 等, 2023](zotero://select/library/items/E2J5KX9I))
    
    - 几十年来，二进制轮廓和基于关键点的骨架一直主导着人类步态识别研究，因为它们很容易从视频帧中提取。尽管它们在实验室环境下的步态识别中取得了成功，但由于步态表征的信息熵较低，它们在现实世界中通常会失败。为了在野外实现准确的步态识别，本文提出了一种名为步态解析序列（GPS）的新型步态表示法。全球定位系统是从视频帧中提取的细粒度人体分割序列，即人体解析序列，因此具有更高的信息熵，可以编码行走过程中细粒度人体部位的形状和动态。此外，为了有效探索 GPS 表示法的能力，我们提出了一种新颖的基于人体解析的步态识别框架，命名为 ParsingGait。ParsingGait 包含一个基于卷积神经网络（CNN）的骨干网和两个轻量级头。第一个头从全球定位系统中提取全局语义特征，而另一个头则通过图卷积网络学习部分级特征的互信息，以模拟人类行走的详细动态。此外，由于缺乏合适的数据集，我们通过扩展大规模且具有挑战性的 Gait3D 数据集，建立了第一个基于解析的野外步态识别数据集，命名为 Gait3D-Parsing。基于 Gait3D-Parsing，我们全面评估了我们的方法和现有的步态识别方法。具体来说，与最先进的基于剪影的方法相比，ParsingGait 的 Rank-1 提高了 17.5%。此外，通过用 GPS 取代剪影，目前的步态识别方法的 Rank-1 准确率提高了约 12.5% ∼ 19.2%。实验结果表明，GPS 表示法显著提高了准确率，并且 ParsingGait 更具优势。

#### **CVPR2023**

- [LIDAR GAIT: Benchmarking 3D Gait Recognition with Point Clouds](https://arxiv.org/abs/2211.10598) - C. Shen et al. (⚡***LidarGait*** [[code]](https://github.com/ShiqiYu/OpenGait))([Shen 等, 2023](zotero://select/library/items/XANQESAV))
    
    - 基于视频的步态识别在受限场景中取得了令人瞩目的成果。然而，视觉相机忽略了人体三维结构信息，这限制了在三维野生环境中进行步态识别的可行性。这项工作不是从图像中提取步态特征，而是从点云中探索精确的三维步态特征，并提出了一个简单而高效的三维步态识别框架，称为 LidarGait。我们提出的方法将稀疏的点云投射到深度图中，以学习具有三维几何信息的表征，其效果明显优于现有的基于点的方法和基于摄像头的方法。由于缺乏点云数据集，我们建立了第一个基于激光雷达的大规模步态识别数据集 SUSTech1K，该数据集由激光雷达传感器和 RGB 摄像机采集。该数据集包含来自 1,050 名受试者的 25,239 个序列，涵盖多种变化，包括可见度、视图、遮挡物、服装、携带和场景。大量实验表明：（1）三维结构信息是步态识别的重要特征。(2) LidarGait 的性能明显优于现有的基于点和剪影的方法，同时它还能提供稳定的跨视角结果。(3) 在室外环境中，激光雷达传感器在步态识别方面优于 RGB 摄像机。

#### **TPAMI2023**

- [Learning Gait Representation from Massive Unlabelled Walking Videos: A Benchmark](https://ieeexplore.ieee.org/document/10242019) - C. Fan et al. (⚡***GaitSSB*** [[code]](https://github.com/ShiqiYu/OpenGait))([Fan 等, 2023](zotero://select/library/items/3V4P8F22))
    
    - 步态描述了个人独特而有区别的行走模式，已成为最有前途的人体识别生物特征之一。作为一项细粒度识别任务，步态识别容易受到多种因素的影响，通常需要大量完整标注的数据，成本高昂且难以满足。本文提出了一种利用对比学习进行步态识别的大规模自监督基准，旨在通过提供翔实的步行先验数据和多样化的真实世界变化，从海量无标签步行视频中学习一般步态表示，以用于实际应用。具体来说，我们收集了一个由 102 万个行走序列组成的大规模无标记步态数据集 GaitLU-1M，并提出了一个概念上简单但经验上强大的基线模型 GaitSSB。实验中，我们在四个广泛使用的步态基准（CASIA-B、OU-MVLP、GREW 和 Gait3D）上对预训练模型进行了评估，无论是否有迁移学习。无监督结果与早期基于模型和基于 GEI 的方法相当，甚至更好。经过迁移学习后，GaitSSB 在大多数情况下都大大优于现有方法，同时也展示了其卓越的泛化能力。进一步的实验表明，预训练可以为 GREW 和 Gait3D 节省约 50% 和 80% 的标注成本。从理论上讲，我们讨论了步态特定对比框架的关键问题，并提出了一些供进一步研究的见解。据我们所知，GaitLU-1M 是第一个大规模无标签步态数据集，而 GaitSSB 则是第一个在上述基准上取得显著无监督结果的方法。

### 2024

#### **MM2024**

- [Gait Recognition in Large-scale Free Environment via Single LiDAR](https://arxiv.org/pdf/2211.12371) - X. Han et al. ✨ **Oral Paper** ✨([Han 等, 2024](zotero://select/library/items/G7FEQTFW))
    
    - 人的步态识别在多媒体中至关重要，它可以在没有直接互动的情况下通过行走模式进行识别，从而加强了智能家居、医疗保健和非侵入式安防等现实世界应用中各种媒体形式的整合。激光雷达捕捉深度的能力使其成为机器人感知的关键，也为现实世界的步态识别带来了希望。本文以单个激光雷达为基础，介绍了用于稳健步态识别的分层多表征特征交互网络（HMRNet）。目前主流的基于激光雷达步态数据集主要来自预定轨迹的受控环境，与真实世界的场景仍有差距。为了促进基于激光雷达的步态识别研究，我们引入了 FreeGait，这是一个来自大规模、无约束环境的综合步态数据集，其中丰富了多模态、多变的 2D/3D 数据。值得注意的是，我们的方法在先前的数据集（SUSTech1K）和 FreeGait 上都取得了一流的性能。

#### **AAAI2024**

- [SkeletonGait: Gait Recognition Using Skeleton Maps](https://arxiv.org/abs/2311.13444) - C. Fan et al. (⚡***SkeletonGait*** [[code]](https://github.com/ShiqiYu/OpenGait))([Fan 等](zotero://select/library/items/ZXX3XP4Z))
    
    - 对于深度步态识别方法来说，表征的选择至关重要。二进制轮廓和骨骼坐标是近期文献中的两种主流表示方法，在许多场景中都取得了显著进步。然而，内在的挑战依然存在，在无约束场景中，剪影并不总能得到保证，而骨骼的结构线索也没有得到充分利用。在本文中，我们介绍了一种名为 "骨骼图 Skeleton Maps"的新型骨骼步态表示法，以及一种基于骨骼的方法 SkeletonGait，该方法可利用人体骨骼图中的结构信息。具体来说，骨骼图将人体关节的坐标表示为高斯近似的热图，呈现出一种没有确切身体结构的剪影式图像。除了在五个流行的步态数据集上取得最先进的性能外，更重要的是，SkeletonGait 揭示了结构特征在描述步态中的重要性以及何时发挥作用的新见解。此外，我们还提出了一种名为 SkeletonGait++ 的多分支架构，以利用骨骼和轮廓的互补特征。实验表明，SkeletonGait++ 在各种情况下都大大优于现有的先进方法。例如，在具有挑战性的 GREW 数据集上，它的排名-1 准确率超过 85%，令人印象深刻。
    - 骨骼Skeleton+轮廓Silhouette 互补融合Fusion

#### **WACV2024**

- [You Can Run but not Hide: Improving Gait Recognition with Intrinsic Occlusion Type Awareness](https://arxiv.org/abs/2312.02290) - A. Gupta et al. ✨ **Oral Paper** ✨([Gupta 和 Chellappa, 2023](zotero://select/library/items/G8NTE4XA))
    
    - 近年来，步态识别技术取得了许多进展，但遮挡问题却在很大程度上被忽视了。这个问题对于在一定范围内从不受控制的室外序列中进行步态识别尤为重要，因为任何微小的障碍物都会影响识别系统。目前的大多数方法在提取步态特征时都假定有完整的身体信息。当身体的某些部分被遮挡时，这些方法可能会产生幻觉，输出损坏的步态特征，因为它们试图寻找输入中根本不存在的身体部分。为了解决这个问题，我们在从视频中提取身份特征时利用了所学到的遮挡类型。因此，在这项工作中，我们提出了一种闭塞感知步态识别方法，该方法可用于在任何最先进的步态识别方法中建立内在闭塞感知模型。我们在具有挑战性的 GREW 和 BRIAR 数据集上进行的实验表明，具有这种遮挡意识的网络在识别任务中的表现要优于在类似遮挡情况下训练的网络。

## 基于模型的步态识别 Model based Gait Recognition（骨骼/Skeleton）

#### **PR2020**

- [A model-based gait recognition method with body pose and human prior knowledge](https://www.sciencedirect.com/science/article/pii/S003132031930370X) - R. Liao et al. (⚡***PoseGait*** [[code]](https://github.com/RijunLiao/PoseGait))([Liao 等, 2020](zotero://select/library/items/GXCXJLJF))
    
    - 我们在本文中提出了一种新颖的基于模型的步态识别方法 PoseGait。步态识别是生物统计学中一项具有挑战性和吸引力的任务。早期的步态识别方法主要基于外观。基于外观的特征通常是从人体轮廓中提取的，这种特征易于计算，而且在识别任务中表现出很高的效率。然而，轮廓形状并不随服装的变化而变化，而且会因光照变化或其他外部因素而发生剧烈变化。除了基于轮廓的特征之外，还有一种基于模型的特征。然而，获取这些特征非常具有挑战性，尤其是在图像分辨率较低的情况下。与之前的方法不同，我们的模型 PoseGait 利用卷积神经网络从图像中估算出的人体三维姿势作为步态识别的输入特征。三维姿势由人体关节的三维坐标定义，不受视角变化和其他外部变化因素的影响。我们根据三维姿势设计时空特征，以提高识别率。我们的方法在 CASIA B 和 CASIA E 两个大型数据集上进行了评估。实验结果表明，所提出的方法可以达到最先进的性能，并且对视图和服装变化具有鲁棒性。

#### **ICIP2021**

- [Gaitgraph: Graph convolutional network for skeleton-based gait recognition](https://ieeexplore.ieee.org/abstract/document/9506717/) - T. Teepe et al. (⚡***GaitGraph*** [[code]](https://github.com/tteepe/GaitGraph))([Teepe 等, 2021](zotero://select/library/items/GAIALW2U))
    
    - 步态识别是一种很有前途的基于视频的生物识别技术，可用于远距离识别个人行走模式。目前，大多数步态识别方法都使用剪影图像来表示每个帧中的人。然而，剪影图像会丢失细粒度的空间信息，而且大多数论文都没有考虑如何在复杂场景中获取这些剪影。此外，剪影图像不仅包含步态特征，还包含其他可识别的视觉线索。因此，这些方法不能被视为严格意义上的步态识别。我们利用最近在人体姿态估计方面取得的进展，直接从 RGB 图像中估计出稳健的骨架姿态，从而以更清晰的步态表示，重新进行基于模型的步态识别。因此，我们提出了 GaitGraph，它将骨架姿势与图卷积网络（GCN）相结合，从而获得一种基于模型的现代步态识别方法。它的主要优点是能更简洁、优雅地提取步态特征，并能利用 GCN 结合强大的时空建模功能。在流行的 CASIA-B 步态数据集上进行的实验表明，我们的方法在基于模型的步态识别方面具有最先进的性能。

#### **Arxiv2022**

- [GaitMixer: skeleton-based gait representation learning via wide-spectrum multi-axial mixer](https://arxiv.org/abs/2210.15491) - E. Pinyoanuntapong (⚡***GaitMixer*** [[code]](https://github.com/exitudio/gaitmixer))([Pinyoanuntapong 等, 2022](zotero://select/library/items/M2SANZ5A))
    
    - 现有的步态识别方法大多基于外观，依赖于从人类行走活动视频数据中提取的轮廓。研究较少的基于骨架的步态识别方法直接从二维/三维人体骨架序列中学习步态动态，理论上，这种方法在服装、发型和携带物品引起的外观变化中更稳健。然而，基于骨骼的解决方案的性能在很大程度上仍然落后于基于外观的解决方案。本文旨在通过提出一种新颖的网络模型--GaitMixer，从骨架序列数据中学习更具辨别力的步态表示，从而缩小这种性能差距。具体而言，GaitMixer 采用异构多轴混合器架构，利用空间自注意混合器和时间大核卷积混合器来学习步态特征图中丰富的多频信号。在广泛使用的步态数据库 CASIA-B 上进行的实验表明，GaitMixer 的性能大大优于之前基于 SOTA 骨架的方法，同时与具有代表性的基于外观的解决方案相比，GaitMixer 的性能也很有竞争力。
- [Spatial Transformer Network on Skeleton-based Gait Recognition](https://arxiv.org/abs/2204.03873) - C. Zhang et al. (⚡***GaitTR*** [[code]](https://github.com/posegait/PoseGait))([Zhang 等, 2022](zotero://select/library/items/HGK93VNS))
    
    - 基于骨架的步态识别模型通常存在鲁棒性问题，因为其 Rank1 准确率从正常行走情况下的 90% 到带大衣行走情况下的 70% 不等。在这项工作中，我们提出了一种最先进的基于骨架的鲁棒步态识别模型，称为 Gait-TR，它是基于空间变换框架和时间卷积网络的组合。与其他基于骨架的步态模型相比，Gait-TR 在著名的步态数据集 CASIA-B 上取得了实质性的改进，具有更高的准确性和更好的鲁棒性。特别是在带大衣行走的情况下，Gait-TR 的 Rank-1 步态识别准确率达到了 90%，高于基于轮廓的模型的最佳结果，而基于轮廓的步态识别模型通常具有更高的准确率。此外，我们在 CASIA-B 上的实验表明，空间变换器从人体骨骼中提取步态特征的效果优于广泛使用的图卷积网络。

#### **CVPR2022**

- [Towards a Deeper Understanding of Skeleton-based Gait Recognition](https://openaccess.thecvf.com/content/CVPR2022W/Biometrics/html/Teepe_Towards_a_Deeper_Understanding_of_Skeleton-Based_Gait_Recognition_CVPRW_2022_paper.html) - T. Teepe et al., CVPRW2022 (⚡***GaitGraph2*** [[code]](https://github.com/tteepe/GaitGraph2))([Teepe 等, 2022](zotero://select/library/items/IFKG4XKV))
    
    - 步态识别是一种前景广阔的生物识别技术，它具有独特的特性，可通过步行模式从远距离识别个人。近年来，大多数步态识别方法都使用人物剪影来提取步态特征。然而，剪影图像可能会丢失细粒度的空间信息，受到（自）遮挡的影响，并且在现实世界中获取具有挑战性。此外，这些剪影还包含其他视觉线索，这些线索并非实际步态特征，可用于识别，但也会欺骗系统。基于模型的方法则不存在这些问题，而且能够表现出身体关节的时间运动，这才是真正的步态特征。人体姿态估计技术的进步为基于模型的步态识别开创了一个新时代，即基于骨骼的步态识别。在这项工作中，我们提出了一种基于图卷积网络（GCN）的方法，该方法将高阶输入和残差网络相结合，为步态识别提供了一种高效的架构。我们在 CASIA-B 和 OUMVLP-Pose 这两个流行的步态数据集上进行了广泛的实验，结果表明，在最大的步态数据集 OUMVLP-Pose 上，我们的方法比最先进的方法（SotA）提高了 3 倍，并具有强大的时间建模能力。最后，我们将我们的方法可视化，以更好地理解基于骨骼的步态识别，并表明我们对真实步态特征进行了建模。

#### **ICCV2023**

- [GPGait: Generalized Pose-based Gait Recognition](https://arxiv.org/abs/2303.05234) - Y. Fu et al. ((⚡***GPGait*** [[code]](https://github.com/BNU-IVC/FastPoseGait)))([Fu 等, 2023](zotero://select/library/items/4PAX3HKC))
    
    - 最近关于基于姿态的步态识别的研究表明，利用这种简单的信息可以获得与基于轮廓的方法相媲美的结果。然而，基于姿态的方法在不同数据集上的泛化能力不如基于轮廓的方法，这一点很少受到关注，但却阻碍了这些方法在现实世界中的应用。为了提高基于姿态的方法在不同数据集上的泛化能力，我们提出了基于姿态的步态识别（GPGait）框架。首先，我们提出了以人为导向的变换（HOT）和一系列以人为导向的描述符（HOD），以获得具有多特征判别能力的统一姿势表示。然后，考虑到 HOT 和 HOD 后的统一表示法存在细微差别，网络提取关键点之间的局部-全局关系就变得至关重要。为此，我们提出了一种部分感知图卷积网络（PAGCN），以实现高效的图分割和局部-全局空间特征提取。在 CASIA-B、OUMVLP-Pose、Gait3D 和 GREW 四个公开步态识别数据集上的实验表明，与现有的基于骨架的方法相比，我们的模型具有更好、更稳定的跨域能力，识别结果与基于剪影的方法相当。

## 步态调查 Gait Survey

#### 2018

- [A survey on gait recognition](https://dl.acm.org/doi/abs/10.1145/3230633) - C. Wan et al., CSUR2018
- [Biometric recognition by gait: A survey of modalities and features](https://www.sciencedirect.com/science/article/pii/S1077314218300079) - P. Connor et al., CVIU2018

#### 2019

- [A survey on gait recognition via wearable sensors](https://dl.acm.org/doi/abs/10.1145/3340293) - MD. Marsico et al., CSUR2019

#### 2022

- [A comprehensive survey on deep gait recognition: algorithms, datasets and challenges](https://arxiv.org/abs/2206.13732) - C. Shen et al., Arxiv 2022
- [Deep gait recognition: A survey](https://ieeexplore.ieee.org/abstract/document/9714177/) - A. Sepas-Moghaddam et al., **TPAMI2022**

## 教程 Tutorial

- Soft Biometrics and Gait - M. Nixon, The IAPR/IEEE Winter School on Biometrics **2022** [[pdf]](https://www.comp.hkbu.edu.hk/wsb2022/slides/Mark_Nixon.pdf)
- Gait Recognition - Y. Yagi, The IAPR/IEEE Winter School on Biometrics **2021** [[pdf]](https://hugefiles.comp.hkbu.edu.hk/album/web/other/wsb2021/slides/Yasushi_Yagi.pdf)
- Human Gait Analysis - Y. Yagi, The IAPR/IEEE Winter School on Biometrics **2020** [[pdf]](https://hugefiles.comp.hkbu.edu.hk/album/web/other/wsb2020/slides/Yasushi_Yagi.pdf)
- Human Gait Analysis - Y. Yagi, The IAPR/IEEE Winter School on Biometrics **2019** [[pdf]](https://hugefiles.comp.hkbu.edu.hk/album/web/other/wsb19/slides/Yasushi_Yagi.pdf)
- Gait and Soft Biometrics - M. Nixon, The IAPR/IEEE Winter School on Biometrics **2018** [[pdf]](https://hugefiles.comp.hkbu.edu.hk/album/web/other/wsb18/slides/Mark_Nixon.pdf)
- Human Identification via Gait Recognition - L. Wang, The IAPR/IEEE Winter School on Biometrics **2017** [[pdf]](https://www.comp.hkbu.edu.hk/wsb17/slides/Liang_Wang.pdf)[[video]](http://hkbutube.lib.hkbu.edu.hk/st/display.php?bibno=b3976435)

## 框架 Framework

**Pytorch**

- [OpenGait: Revisiting Gait Recognition Toward Better Practicality](https://arxiv.org/abs/2211.06597) - C. Fan et al., CVPR2023 (⚡ ***OpenGait*** [[Link]](https://github.com/ShiqiYu/OpenGait)) ✨ **Highlight Paper** ✨([Fan 等, 2023](zotero://select/library/items/AQ4Q9N6E))
    
    - 步态识别是最重要的远距离识别技术之一，在研究界和工业界越来越受欢迎。尽管在室内数据集方面取得了重大进展，但许多证据表明，步态识别技术在野外表现不佳。更重要的是，我们还发现从室内数据集中得出的一些结论无法推广到实际应用中。因此，本文的主要目标是提出一项综合性基准研究，以获得更好的实用性，而不仅仅是一个特定的模型，以获得更好的性能。为此，我们首先开发了一个灵活高效的步态识别代码库，名为 OpenGait。在 OpenGait 的基础上，我们通过重新进行消融实验，对步态识别的最新发展进行了深入研究。令人鼓舞的是，我们发现了某些先前工作中的不完美之处，并提出了新的见解。受这些发现的启发，我们开发了一个结构简单、经验强大且实用稳健的基线模型--GaitBase。实验中，我们在多个公开数据集上综合比较了 GaitBase 与当前许多步态识别方法，结果表明，无论室内室外，GaitBase 在大多数情况下都取得了显著的高性能。
- [FastPoseGait](https://github.com/BNU-IVC/FastPoseGait) - S. Meng et al. (⚡ ***FastPoseGait*** [[Link]](https://github.com/BNU-IVC/FastPoseGait))