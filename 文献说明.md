# 文献说明

## 1\. Gait3D (及其 SOTA 模型 SMPLGait)

([Zheng 等, 2022](zotero://select/library/items/GNSK8YW7))

- **主要内容:**
    
    - 这是一篇旨在解决“野外”（in-the-wild）步态识别问题的论文，它指出现有的2D表示（如剪影）在非受控场景中会因3D投影到2D而丢失视角、体型和动态等关键信息 1。
    - 为此，该研究构建并发布了 **Gait3D**——**首个**基于大规模3D表示的步态识别数据集 2。[https://gait3d.github.io](https://gait3d.github.io/)
    - 该数据集包含4000名受试者和超过25000个序列，采集于一个无约束的室内场景（超市）3。([Huang 等, 2025](zotero://select/library/items/JXJQU5MD))
    - 它提供**多模态数据**，核心是**3D SMPL模型**（一种密集的3D人体网格，能提供体型、视角和动态信息），同时也提供传统的**2D剪影（Silhouettes）和2D/3D关键点（Keypoints / 骨骼）**2。
- **创新点:**
    
    - **首创3D数据集:** 最大的创新在于构建并开源了Gait3D这一首个大规模3D步态数据集，将研究重点从2D表示引向了更适合“野外”场景的密集3D表示 2。
    - **提出SMPLGait模型:** 论文还提出了一个名为 **SMPLGait** 的多模态基线模型。该模型具有两个分支：一个分支从**2D剪影**中学习外观特征；另一个分支（3D-STN）则从**3D SMPL模型**中学习视角和体型知识 1。
    - **特征归一化:** SMPLGait的**核心机制**是利用3D-STN分支学到的空间变换矩阵，去“归一化”2D外观特征分支，以此来矫正因视角变化导致的外观失真，证明了2D和3D表示的互补性 1。

## 2\. GREW (Gait REcognition in the Wild)

([Guo 等, 2024](zotero://select/library/items/XJIYLHRQ))，[http://www.grew-benchmark.org](http://www.grew-benchmark.org/)

- **主要内容:**
    
    - **GREW** 是一个用于“野外”步态识别的大规模基准（Benchmark）数据集 4。
    - 它被构建的动机是，现有的受控（实验室）数据集无法满足真实世界应用的需求 4。
    - 其规模空前，包含 **26,345** 名受试者、**128,671** 个序列，采集自数百个摄像头的自然视频流 4。
    - 它提供的多模态数据包括：**剪影（Silhouettes）**、**步态能量图（GEIs）**、**光流（Optical flow）以及2D/3D姿态（Poses / 骨骼）**4。
- **创新点:**
    
    - **首个“野外”大规模基准:** 这是首个真正意义上的“野外”大规模步态数据集，其数据量和场景复杂度（如复杂的背景、遮挡、衣着、光照和多样化的视角）远超以往 4。
    - **引入干扰项集 (Distractor Set):** 该数据集的一大创举是额外增加了一个包含超过 **23.3万** 个序列的“干扰项集”。这使得评估环境非常接近真实世界的安防应用（即在海量无关人员中检索目标），极大地提升了基准的实用性和挑战性 4。
    - **提出SPOSGait模型:** 该论文也提出了一个配套的强基线模型 **SPOSGait**，该模型基于神经架构搜索（NAS）技术，在GREW和其他数据集上均取得了SOTA（State-of-the-Art）性能 6。

## 3\. SkeletonGait++

([Fan 等](zotero://select/library/items/ZXX3XP4Z))

- **主要内容:**
    
    - **SkeletonGait++** 是一个多模态（双分支）架构，旨在利用**剪影（Silhouettes）和骨骼图（Skeleton Maps）**之间的互补特征 7。
    - “骨骼图”是一种将稀疏的骨骼关键点坐标渲染成的2D图像表征，使其数据格式与剪影图保持一致，从而便于使用CNN进行并行处理和融合 8。
    - 该模型在早期阶段（如Stage1）使用共享网络架构处理两种模态，随后通过一个融合模块逐帧聚合两种特征 8。
- **创新点:**
    
    - **Attention Fusion 机制:** 其核心创新是提出了一种轻量级且高效的**“注意力融合”（Attention Fusion）机制。这并非基于Transformer的交叉注意力，而是一种卷积注意力模块** 7。
    - **融合架构原理:** 该机制的具体实现步骤如下：
        
        1. 将剪影分支和骨骼图分支的特征图（Feature Maps）在**通道维度上进行拼接 (Concatenate)** 7。
        2. 将拼接后的特征输入一个“小型网络” (small network) 以形成跨分支的理解 7。
        3. 这个“小型网络”被明确定义为由三个卷积层组成：**一个压缩的1×1卷积→一个常规的3×3卷积→一个扩张的1×1卷积** 8。([Fan 等, 2025](zotero://select/library/items/Z7CLAHDV))
        4. 最后通过一个 `Softmax` 层生成逐元素的注意力权重（Mask），再乘回原特征图 8。

## 4\. MultiGait++ (及其 C2Fusion)

([Jin 等](zotero://select/library/items/DHF5MQJE))

- **主要内容:**
    
    - **MultiGait++** 是一个先进的多模态融合框架，它旨在融合**剪影（Silhouette）、人体解析（Human Parsing）和光流（Optical Flow）**等多种模态 10。
    - 该模型的目标是最大化地从给定模态中提取多样化特征，以增强步态表征的判别能力 10。
- **创新点:**
    
    - **C2Fusion 策略:** 其核心创新是提出了一种名为 **C2Fusion** 的新型融合策略 10。
    - **融合原理（共享与独特）:** C2Fusion 的核心思想是“提取跨模态的共享特征 (Commonalities)”**，同时**“鼓励每个模态强调其独特属性 (Unique Attributes)” 10。
    - **机制优势:** 这种“保留共性，凸显差异”的设计，迫使模型更深入地解耦和重组不同模态的信息（例如，所有模态都同意的“运动”信息，以及只有Parsing模态知道的“背包”信息），从而学习到更丰富、鲁棒性更强的步态特征 10。该策略在多个基准测试中被证明优于简单的特征拼接或常规的注意力融合 10。

## 5\. GaitCSF

([Wei 等, 2025](zotero://select/library/items/8X5IXH8Y))

- **主要内容:**
    
    - **GaitCSF** 是一个多模态步态识别网络，它采用三分支并行架构，分别优化**轮廓（Contour）**特征、**姿态热图（Heatmap）**特征以及它们的融合特征，以实现互补增强 14。
- **创新点:**
    
    - **CFS 模块:** 其核心创新是设计了一个**“基于通道洗牌的特征选择性调节模块” (CFS)** 14。
    - **融合原理（高效轻量）:** 该模块的设计重点是**效率**和**轻量化** 14。
    - **机制架构:** 它通过**通道分组 (Channel Grouping)**，在组内并行处理**通道统计**（捕获通道间依赖）和**空间统计**（使用组归一化），然后利用（源自 ShuffleNet 的）**“通道洗牌” (Channel Shuffling)** 操作在不同组之间交换信息 14。
    - **机制优势:** 这种设计实现了“轻量级参数设计”下的“自适应特征增强”，在保持较低计算成本的同时，实现了有效的多模态特征调节和融合 14。

## 6\. OpenGait

([Fan 等, 2025](zotero://select/library/items/Z7CLAHDV))

- **主要内容:**
    
    - **OpenGait** 不是一个单一的模型或数据集，而是一个用于步态识别的**开源软件基准框架 (Benchmark Framework)** 15。
    - [https://github.com/ShiqiYu/OpenGait](https://github.com/ShiqiYu/OpenGait)
    - 它的目标是“重新审视步态识别以实现更好的实用性” 17，为研究社区提供一个统一且可扩展的平台。([Sun 等, 2025](zotero://select/library/items/RI5DEKNY))
- **创新点:**
    
    - **公平比较 (Fair Comparison):** 它的主要贡献是提供了一个统一的代码库，该代码库复现了多种SOTA模型（如 SkeletonGait++、DeepGaitV2 等）8。([Fan 等](zotero://select/library/items/ZXX3XP4Z); [Li 等, 2025](zotero://select/library/items/LWNL962U); [Fan 等, 2025](zotero://select/library/items/Z7CLAHDV))
    - **可插拔模块:** 它允许研究者在“公平的条件”下 19，方便地测试和比较不同的网络骨干、模块和融合策略（如 OpenGait 明确支持对 `Add Fusion`, `Concat Fusion` 和 `Attention Fusion` 等不同融合方式进行基准测试）11。([Jin 等](zotero://select/library/items/DHF5MQJE); [Fan 等, 2025](zotero://select/library/items/Z7CLAHDV))
    - **提出GaitBase:** 在提供这个框架的同时，OpenGait也提出并实现了一个简单但性能强大的基线模型——**GaitBase** 17。([Sun 等, 2025](zotero://select/library/items/RI5DEKNY))